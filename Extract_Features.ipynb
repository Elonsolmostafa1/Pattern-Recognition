{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from PIL import Image, ImageEnhance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data of Males and Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Male_training_data='Data_split\\\\train\\\\Males\\\\*.jpg'\n",
    "Female_training_data='Data_split\\\\train\\\\Females\\\\*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing (image) : \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)  # convert color from RGB to GRAY\n",
    "    height, width = image.shape # get image dimensions\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 0) #decrease noise for dialation\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30) # apply threshold on blured image\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)  # apply threshold on original image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 20)) \n",
    "    img = cv2.dilate(img, kernel, iterations=8)\n",
    "    contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0] \n",
    "    biggest_contour = functools.reduce(lambda c1, c2: c1 if cv2.contourArea(c1) > cv2.contourArea(c2) else c2,contours) #find the biggest contour for text area\n",
    "    x, y, w, h = cv2.boundingRect(biggest_contour) # find smallest rect that can contain the text area after dialation\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- COLD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some constants for cold feature extraction \n",
    "N_RHO_BINS = 7\n",
    "N_ANGLE_BINS = 12\n",
    "N_BINS = N_RHO_BINS * N_ANGLE_BINS\n",
    "BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "R_INNER = 5.0\n",
    "R_OUTER = 35.0\n",
    "K_S = np.arange(3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_pixels(bw_image):\n",
    "        contours, _= cv2.findContours(bw_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "        # contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "        \n",
    "        img2 = bw_image.copy()[:,:,np.newaxis]\n",
    "        img2 = np.concatenate([img2, img2, img2], axis = 2)\n",
    "        return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cold_features(bw_image, approx_poly_factor = 0.01):\n",
    "    \n",
    "        contours = get_contour_pixels(bw_image)\n",
    "        \n",
    "        rho_bins_edges = np.log10(np.linspace(R_INNER, R_OUTER, N_RHO_BINS))\n",
    "        feature_vectors = np.zeros((len(K_S), N_BINS))\n",
    "        \n",
    "        # print([len(cnt) for cnt in contours])\n",
    "        for j, k in enumerate(K_S):\n",
    "            hist = np.zeros((N_RHO_BINS, N_ANGLE_BINS))\n",
    "            for cnt in contours:\n",
    "                epsilon = approx_poly_factor * cv2.arcLength(cnt,True)\n",
    "                cnt = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "                n_pixels = len(cnt)\n",
    "                \n",
    "                point_1s = np.array([point[0] for point in cnt])\n",
    "                x1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "                point_2s = np.array([cnt[(i + k) % n_pixels][0] for i in range(n_pixels)])\n",
    "                x2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "                \n",
    "                thetas = np.degrees(np.arctan2(y2s - y1s, x2s - x1s) + np.pi)\n",
    "                rhos = np.sqrt((y2s - y1s) ** 2 + (x2s - x1s) ** 2)\n",
    "                rhos_log_space = np.log10(rhos)\n",
    "                \n",
    "                quantized_rhos = np.zeros(rhos.shape, dtype=int)\n",
    "                for i in range(N_RHO_BINS):\n",
    "                    quantized_rhos += (rhos_log_space < rho_bins_edges[i])\n",
    "                    \n",
    "                for i, r_bin in enumerate(quantized_rhos):\n",
    "                    theta_bin = int(thetas[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                    hist[r_bin - 1, theta_bin] += 1\n",
    "                \n",
    "            normalised_hist = hist / hist.sum()\n",
    "            feature_vectors[j] = normalised_hist.flatten()\n",
    "            \n",
    "        return feature_vectors.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- HINGE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
