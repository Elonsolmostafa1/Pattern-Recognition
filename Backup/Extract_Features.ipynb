{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "from PIL import Image, ImageEnhance\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.feature import local_binary_pattern\n",
    "from sklearn.preprocessing import normalize\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data of Males and Females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "Male_training_data='Data_split\\\\train\\\\Males\\\\*.jpg'\n",
    "Female_training_data='Data_split\\\\train\\\\Females\\\\*.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing (image) : \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)  # convert color from RGB to GRAY\n",
    "    height, width = image.shape # get image dimensions\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 0) #decrease noise for dialation\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30) # apply threshold on blured image\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)  # apply threshold on original image\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 20)) \n",
    "    img = cv2.dilate(img, kernel, iterations=8)\n",
    "    contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0] \n",
    "    biggest_contour = functools.reduce(lambda c1, c2: c1 if cv2.contourArea(c1) > cv2.contourArea(c2) else c2,contours) #find the biggest contour for text area\n",
    "    x, y, w, h = cv2.boundingRect(biggest_contour) # find smallest rect that can contain the text area after dialation\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- COLD features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some constants for cold feature extraction \n",
    "N_RHO_BINS = 7\n",
    "N_ANGLE_BINS = 12\n",
    "N_BINS = N_RHO_BINS * N_ANGLE_BINS\n",
    "BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "R_INNER = 5.0\n",
    "R_OUTER = 35.0\n",
    "K_S = np.arange(3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contour_pixels(bw_image):\n",
    "        contours, _= cv2.findContours(bw_image, cv2.RETR_TREE, cv2.CHAIN_APPROX_NONE) \n",
    "        # contours = imutils.grab_contours(contours)\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)[1:]\n",
    "        \n",
    "        img2 = bw_image.copy()[:,:,np.newaxis]\n",
    "        img2 = np.concatenate([img2, img2, img2], axis = 2)\n",
    "        return contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cold_features(bw_image, approx_poly_factor = 0.01):\n",
    "    \n",
    "        contours = get_contour_pixels(bw_image)\n",
    "        \n",
    "        rho_bins_edges = np.log10(np.linspace(R_INNER, R_OUTER, N_RHO_BINS))\n",
    "        feature_vectors = np.zeros((len(K_S), N_BINS))\n",
    "        \n",
    "        # print([len(cnt) for cnt in contours])\n",
    "        for j, k in enumerate(K_S):\n",
    "            hist = np.zeros((N_RHO_BINS, N_ANGLE_BINS))\n",
    "            for cnt in contours:\n",
    "                epsilon = approx_poly_factor * cv2.arcLength(cnt,True)\n",
    "                cnt = cv2.approxPolyDP(cnt,epsilon,True)\n",
    "                n_pixels = len(cnt)\n",
    "                \n",
    "                point_1s = np.array([point[0] for point in cnt])\n",
    "                x1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "                point_2s = np.array([cnt[(i + k) % n_pixels][0] for i in range(n_pixels)])\n",
    "                x2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "                \n",
    "                thetas = np.degrees(np.arctan2(y2s - y1s, x2s - x1s) + np.pi)\n",
    "                rhos = np.sqrt((y2s - y1s) ** 2 + (x2s - x1s) ** 2)\n",
    "                rhos_log_space = np.log10(rhos)\n",
    "                \n",
    "                quantized_rhos = np.zeros(rhos.shape, dtype=int)\n",
    "                for i in range(N_RHO_BINS):\n",
    "                    quantized_rhos += (rhos_log_space < rho_bins_edges[i])\n",
    "                    \n",
    "                for i, r_bin in enumerate(quantized_rhos):\n",
    "                    theta_bin = int(thetas[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                    hist[r_bin - 1, theta_bin] += 1\n",
    "                \n",
    "            normalised_hist = hist / hist.sum()\n",
    "            feature_vectors[j] = normalised_hist.flatten()\n",
    "            \n",
    "        return feature_vectors.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- HINGE features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define some constants for hinge \n",
    "N_ANGLE_BINS = 40\n",
    "BIN_SIZE = 360 // N_ANGLE_BINS\n",
    "LEG_LENGTH = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hinge_features(bw_image):\n",
    "        \n",
    "        contours = get_contour_pixels(bw_image)\n",
    "        \n",
    "        hist = np.zeros((N_ANGLE_BINS, N_ANGLE_BINS))\n",
    "            \n",
    "        # print([len(cnt) for cnt in contours])\n",
    "        for cnt in contours:\n",
    "            n_pixels = len(cnt)\n",
    "            if n_pixels <= LEG_LENGTH:\n",
    "                continue\n",
    "            \n",
    "            points = np.array([point[0] for point in cnt])\n",
    "            xs, ys = points[:, 0], points[:, 1]\n",
    "            point_1s = np.array([cnt[(i + LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "            point_2s = np.array([cnt[(i - LEG_LENGTH) % n_pixels][0] for i in range(n_pixels)])\n",
    "            x1s, y1s = point_1s[:, 0], point_1s[:, 1]\n",
    "            x2s, y2s = point_2s[:, 0], point_2s[:, 1]\n",
    "            \n",
    "            phi_1s = np.degrees(np.arctan2(y1s - ys, x1s - xs) + np.pi)\n",
    "            phi_2s = np.degrees(np.arctan2(y2s - ys, x2s - xs) + np.pi)\n",
    "            \n",
    "            indices = np.where(phi_2s > phi_1s)[0]\n",
    "            \n",
    "            for i in indices:\n",
    "                phi1 = int(phi_1s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                phi2 = int(phi_2s[i] // BIN_SIZE) % N_ANGLE_BINS\n",
    "                hist[phi1, phi2] += 1\n",
    "                \n",
    "        normalised_hist = hist / np.sum(hist)\n",
    "        feature_vector = normalised_hist[np.triu_indices_from(normalised_hist, k = 1)]\n",
    "        \n",
    "        return feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- LBP Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_LBP_features (img) :\n",
    "    radius = 2\n",
    "    n_points = 16 * radius\n",
    "    lbp = local_binary_pattern(img, n_points, radius, method='nri_uniform')\n",
    "    n_bins = n_points * (n_points - 1) + 3\n",
    "    lbp_hist = np.histogram(lbp.ravel(), bins=np.arange(n_bins + 1), density=True)[0]\n",
    "    return lbp_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_test(features, times=100, test_size=0.2, **kwargs):\n",
    "    tr_ac, ts_ac, mal, fem = 0, 0, 0, 0\n",
    "    for i in range(times):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(features[:,:-1], features[:,-1], test_size=test_size)\n",
    "        clf = svm.SVC(**kwargs)\n",
    "        clf.fit(X_train, y_train)\n",
    "        tr_ac += clf.score(X_train, y_train)\n",
    "        ts_ac += clf.score(X_test, y_test)\n",
    "        mal += np.sum(clf.predict(features[:,:-1]) == 1) / len(features[:,:-1])\n",
    "        fem += np.sum(clf.predict(features[:,:-1]) == 0) / len(features[:,:-1])\n",
    "    ret = ts_ac * 100 / times, tr_ac * 100 / times, mal * 100 / times, fem * 100 / times\n",
    "    print('male_predict% = {}\\nfemale_predict% = {}'.format(*ret[2:]))\n",
    "    return ret[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Feature extaction using Hinge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "male_predict% = 67.4636678200692\n",
      "female_predict% = 32.5363321799308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(70.51724137931033, 88.99999999999996)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LBP_features = []\n",
    "for file in glob.glob(Male_training_data):    \n",
    "    img = cv2.imread(file)  #read male images\n",
    "    img = Preprocessing(img)\n",
    "    LBP_features.append(np.append(get_LBP_features(img),1))\n",
    "\n",
    "for file in glob.glob(Female_training_data):    \n",
    "    img = cv2.imread(file)  #read female images\n",
    "    img = Preprocessing(img)\n",
    "    LBP_features.append(np.append(get_LBP_features(img),0))\n",
    "LBP_features = np.array(LBP_features)\n",
    "LBP_features[:,:-1] = normalize(LBP_features[:,:-1], axis=0) \n",
    "svm_test(LBP_features,C=10,kernel=\"rbf\") \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "569f545527bfb29d6fb9aacc607f33a145e1de933e11224bb20d6923ac7349a0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
