{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing (image) : \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    height, width = image.shape\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 0) #decrease noise for dialation\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 20))\n",
    "    img = cv2.dilate(img, kernel, iterations=8)\n",
    "    contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0] \n",
    "    biggest_contour = functools.reduce(lambda c1, c2: c1 if cv2.contourArea(c1) > cv2.contourArea(c2) else c2,contours) #find the biggest contour for text area\n",
    "    x, y, w, h = cv2.boundingRect(biggest_contour) # find smallest rect that can contain the text area after dialation\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"..\\\\Data_split\\\\train\\\\Females\\\\F1.jpg\")\n",
    "img = Preprocessing(image)\n",
    "resized_image = cv2.resize(image.astype('float'), (64, 128))\n",
    "fd,hog_image = hog(resized_image,orientations=9,pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=True)\n",
    "hog_image = np.array(hog_image)\n",
    "hog_image = hog_image.ravel() \n",
    "print(hog_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG (img):\n",
    "    resized_image = cv2.resize(image.astype('float'), (64, 128))\n",
    "    fd,hog_image = hog(resized_image,orientations=9,pixels_per_cell=(8,8),cells_per_block=(2,2),visualize=True)\n",
    "    hog_image = np.array(hog_image)\n",
    "    hog_image = hog_image.ravel() \n",
    "    return hog_image"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
