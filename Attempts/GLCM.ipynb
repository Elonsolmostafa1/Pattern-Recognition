{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32md:\\Third Year 2nd\\Projects\\NN Project\\Pattern-Recognition\\Attempts\\GLCM.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Third%20Year%202nd/Projects/NN%20Project/Pattern-Recognition/Attempts/GLCM.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcv2\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Third%20Year%202nd/Projects/NN%20Project/Pattern-Recognition/Attempts/GLCM.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m \u001b[39mimport\u001b[39;00m svm\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Third%20Year%202nd/Projects/NN%20Project/Pattern-Recognition/Attempts/GLCM.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import glob\n",
    "from skimage.feature import greycomatrix, greycoprops\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import functools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_glcm_features(gray_scale_img):\n",
    "    \n",
    "    #size of co-occ matrix = number of gray levels\n",
    "    image_array = np.array(gray_scale_img)\n",
    "    #print('first pixel= ', image_array[0][0])\n",
    "    coocurrence_matrix = greycomatrix(image_array, [1], [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4])\n",
    "    contrast = greycoprops(coocurrence_matrix, 'contrast')\n",
    "    homogeneity = greycoprops(coocurrence_matrix, 'homogeneity')\n",
    "    #mean = greycoprops(coocurrence_matrix, 'mean')\n",
    "    energy = greycoprops(coocurrence_matrix, 'energy')\n",
    "    #entropy = greycoprops(coocurrence_matrix, 'entropy')\n",
    "    #variance = greycoprops(coocurrence_matrix, 'variance')\n",
    "    correlation = greycoprops(coocurrence_matrix, 'correlation')\n",
    "    return contrast, homogeneity, energy, correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing (image) : \n",
    "    image = cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
    "    height, width = image.shape\n",
    "    img = cv2.GaussianBlur(image, (9, 9), 0) #decrease noise for dialation\n",
    "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)\n",
    "    image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY_INV, 101, 30)\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 20))\n",
    "    img = cv2.dilate(img, kernel, iterations=8)\n",
    "    contours = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0] \n",
    "    biggest_contour = functools.reduce(lambda c1, c2: c1 if cv2.contourArea(c1) > cv2.contourArea(c2) else c2,contours) #find the biggest contour for text area\n",
    "    x, y, w, h = cv2.boundingRect(biggest_contour) # find smallest rect that can contain the text area after dialation\n",
    "    image = image[y:y + h, x:x + w]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01730614 0.0246604  0.01289823 0.02066758 0.99134693 0.9876698\n",
      " 0.99355089 0.98966621 0.94120776 0.93742761 0.94346913 0.93945855\n",
      " 0.82180902 0.74623261 0.86721223 0.78732066]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01045092 0.01509454 0.00916938 0.01373563 0.99477454 0.99245273\n",
      " 0.99541531 0.99313218 0.96143524 0.95905161 0.96207619 0.95973941\n",
      " 0.83995662 0.76903166 0.85963255 0.78982498]\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"..\\\\Data_split\\\\train\\\\Females\\\\F1.jpg\")\n",
    "img = Preprocessing(image)\n",
    "contrast, homogeneity, energy, correlation= get_all_glcm_features((img * 255).astype(np.uint8))\n",
    "features=[]\n",
    "features.append(contrast.ravel())\n",
    "features.append(homogeneity.ravel())\n",
    "features.append(energy.ravel())\n",
    "features.append(correlation.ravel())\n",
    "features=(np.array(features)).ravel()\n",
    "print(features)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fbc768028c3e6ead51d9a200ddcb2ec858ae62844dcd1994729a8279be9b48f2"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
